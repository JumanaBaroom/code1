{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(177,)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_92 (Conv1D)           (None, 4088, 10)          17710     \n",
      "_________________________________________________________________\n",
      "conv1d_93 (Conv1D)           (None, 4079, 10)          1010      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_46 (MaxPooling (None, 2039, 10)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_94 (Conv1D)           (None, 2030, 30)          3030      \n",
      "_________________________________________________________________\n",
      "conv1d_95 (Conv1D)           (None, 2021, 30)          9030      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_47 (MaxPooling (None, 1010, 30)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_96 (Conv1D)           (None, 1001, 60)          18060     \n",
      "_________________________________________________________________\n",
      "conv1d_97 (Conv1D)           (None, 992, 60)           36060     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_48 (MaxPooling (None, 496, 60)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_98 (Conv1D)           (None, 487, 90)           54090     \n",
      "_________________________________________________________________\n",
      "conv1d_99 (Conv1D)           (None, 478, 90)           81090     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_49 (MaxPooling (None, 239, 90)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_100 (Conv1D)          (None, 230, 120)          108120    \n",
      "_________________________________________________________________\n",
      "conv1d_101 (Conv1D)          (None, 221, 120)          144120    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_50 (MaxPooling (None, 110, 120)          0         \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 110, 50)           6050      \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 110, 20)           1020      \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 110, 5)            105       \n",
      "=================================================================\n",
      "Total params: 479,495\n",
      "Trainable params: 479,495\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected conv1d_92_input to have 3 dimensions, but got array with shape (11500, 177)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-55011a10b411>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;31m#X_train = np.reshape(X_train,(X_train.shape[0], X_train.shape[1],1))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m    950\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    951\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 952\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m    953\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    954\u001b[0m         \u001b[0mdo_validation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    749\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    750\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 751\u001b[0;31m             exception_prefix='input')\n\u001b[0m\u001b[1;32m    752\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda2/lib/python2.7/site-packages/keras/engine/training_utils.pyc\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    126\u001b[0m                         \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m                         \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' dimensions, but got array '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m                         'with shape ' + str(data_shape))\n\u001b[0m\u001b[1;32m    129\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m                     \u001b[0mdata_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking input: expected conv1d_92_input to have 3 dimensions, but got array with shape (11500, 177)"
     ]
    }
   ],
   "source": [
    "#MLP for Pima Indians Dataset with 10-fold cross validation\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LeakyReLU\n",
    "import pandas as pd\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Conv2D, MaxPooling2D, Conv1D, MaxPooling1D\n",
    "from keras.layers import Input, Flatten, Dense, Dropout, Convolution2D, Conv2D, MaxPooling2D, Lambda, GlobalMaxPooling2D, GlobalAveragePooling2D, BatchNormalization, Activation, AveragePooling2D, Concatenate\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.utils import np_utils\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.svm import SVR\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "dataset = np.loadtxt(\"datalast.csv\",delimiter=\",\")\n",
    "X = dataset[:,0:177] #الفيتشرز\n",
    "y = dataset[:,177]\n",
    "\n",
    "print(X[0].shape)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "kfold = KFold(n_splits=10, random_state=None, shuffle=False)\n",
    "# enumerate splits\n",
    "for train, test in kfold.split(X):\n",
    "#print(\"train:\",train ,\"test:\",test)\n",
    " \"\"\"\n",
    "print(len(train))\n",
    "print(len(test))\n",
    "X_train, X_test = X[train], X[test] \n",
    "y_train, y_test = y[train], y[test]\n",
    "print(len(X_train))\n",
    "print(len(X_test))\n",
    "print(len(y_train))\n",
    "print(len(y_test))\n",
    "\n",
    "print(\"__________\")\n",
    "print(\"hhoh\",X_train.shape)\n",
    " \"\"\"\n",
    " # create model\n",
    "# 1D CNN neural network\n",
    "model = Sequential()\n",
    "model.add(Conv1D(filters=10, kernel_size=10, strides=1,activation='relu', input_shape=(4097,177)))\n",
    "model.add(Conv1D(filters=10, kernel_size=10, strides=1))\n",
    "model.add(MaxPooling1D(2))\n",
    "model.add(Conv1D(30,10,activation='relu', strides=1))\n",
    "model.add(Conv1D(30,10,activation='relu', strides=1))\n",
    "model.add(MaxPooling1D(2))\n",
    "model.add(Conv1D(60,10,activation='relu', strides=1))\n",
    "model.add(Conv1D(60,10,activation='relu', strides=1))\n",
    "model.add(MaxPooling1D(2))\n",
    "model.add(Conv1D(90,10,activation='relu', strides=1))\n",
    "model.add(Conv1D(90,10,activation='relu', strides=1))\n",
    "model.add(MaxPooling1D(2))\n",
    "model.add(Conv1D(120,10,activation='relu', strides=1))\n",
    "model.add(Conv1D(120,10,activation='relu', strides=1))\n",
    "model.add(MaxPooling1D(2))\n",
    "#model.add(Flatten())\n",
    "model.add(Dense(50))\n",
    "model.add(Dense (20))\n",
    "model.add(Dense (5,activation='softmax'))\n",
    "print(model.summary())\n",
    "\n",
    "# Compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "#X_train = np.reshape(X_train,(X_train.shape[0], X_train.shape[1],1))\n",
    "model.fit(X, y_train ,epochs=15, batch_size=3, verbose=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
