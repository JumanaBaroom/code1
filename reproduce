import numpy as np
import pandas as pd
from keras.models import Sequential
from keras.layers import LeakyReLU
import keras
from keras.models import Sequential, Model
from keras.layers import Dense, Dropout, Flatten, Reshape, GlobalAveragePooling1D
from keras.layers import Conv2D, MaxPooling2D, Conv1D, MaxPooling1D
from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau
from keras.layers import Input, Flatten, Dense, Dropout, Convolution2D, Conv2D, MaxPooling2D, Lambda, GlobalMaxPooling2D, GlobalAveragePooling2D, BatchNormalization, Activation, AveragePooling2D, Concatenate
from keras.preprocessing.image import ImageDataGenerator
from keras.utils import np_utils
from sklearn.model_selection import KFold
from sklearn.preprocessing import MinMaxScaler
from scipy import stats
from sklearn.model_selection import StratifiedKFold
from sklearn.model_selection import KFold
from sklearn.model_selection import train_test_split


dataset = np.loadtxt("ofor10 comma.csv",delimiter=",")
print(dataset)

x=dataset[1:40969,]
y=dataset[1,]
x = x.transpose()

x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=0)

print(x_train.shape)
print (x_train.ndim)

""""
kfold = KFold(n_splits=10, random_state=None, shuffle=False)
# enumerate splits
for train, test in kfold.split(X):
#print("train:",train ,"test:",test)
""""
# 1D CNN neural network
model= Sequential()
model.add(Conv1D(4, 6, strides=1,input_shape=(4097,4)))
model.add(LeakyReLU(alpha=0.1))
model.add(MaxPooling1D(4, strides=2))
model.add(Conv1D(4, 5, strides=1))
model.add(LeakyReLU(alpha=0.1))
model.add(MaxPooling1D(4, strides=2))
model.add(Conv1D(10, 4,strides=1))
model.add(LeakyReLU(alpha=0.1))
model.add(MaxPooling1D(10, strides=2))
model.add(Conv1D(10, 4, strides=1))
model.add(LeakyReLU(alpha=0.1))
model.add(MaxPooling1D(10, strides=2))
model.add(Conv1D(15, 4, strides=1))
model.add(LeakyReLU(alpha=0.1))
model.add(MaxPooling1D(15, strides=2))
model.add(Dense (50))
model.add(Dense (20))
model.add(Dense (3,activation='softmax'))
print(model.summary())

# Compile model
model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])
# Fit the model
model.fit(x_train, y_train, epochs=150, batch_size=3, verbose=0)

#plt.plot(history.history['acc'], "g--", label="Accuracy of training data")
# evaluate the model
#scores = model.evaluate(x_test, x_test, verbose=0)

#print("%s: %.2f%%" % (model.metrics_names[1], scores[1]*100))
#cvscores.append(scores[1] * 100)
#print("%.2f%% (+/- %.2f%%)" % (numpy.mean(cvscores), numpy.std(cvscores)))

#print("\n--- Fit the model ---\n")

"""

# Hyper-parameters
BATCH_SIZE = 3
EPOCHS = 150
# Enable validation to use ModelCheckpoint and EarlyStopping callbacks.
history = model_m.fit(X,
                    Y,
                    batch_size=BATCH_SIZE,
                    epochs=EPOCHS,
                    callbacks=callbacks_list,
                    validation_split=0.2,
                    verbose=1)
                    def create_model(x_train, y_train, x_test, y_test):

"""
