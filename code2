#MLP for Pima Indians Dataset with 10-fold cross validation

import keras
from keras.models import Sequential
from keras.layers import Dense
from sklearn.model_selection import StratifiedKFold
from keras.models import Sequential
from keras.layers import LeakyReLU
import pandas as pd
import math
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split, StratifiedKFold
from keras.models import Sequential, Model
from keras.layers import Conv2D, MaxPooling2D, Conv1D, MaxPooling1D
from keras.layers import Input, Flatten, Dense, Dropout, Convolution2D, Conv2D, MaxPooling2D, Lambda, GlobalMaxPooling2D, GlobalAveragePooling2D, BatchNormalization, Activation, AveragePooling2D, Concatenate
from keras.preprocessing.image import ImageDataGenerator
from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau
from keras.utils import np_utils
from sklearn.model_selection import KFold
from sklearn.preprocessing import MinMaxScaler
from sklearn.svm import SVR
import numpy as np


# fix random seed for reproducibility
dataset = np.loadtxt("datalast.csv",delimiter=",")
X = dataset[:,0:177] #الفيتشرز
y = dataset[:,177]

print(X[0].shape)

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)

kfold = KFold(n_splits=10, random_state=None, shuffle=False)
# enumerate splits
for train, test in kfold.split(X):
#print("train:",train ,"test:",test)
 """
print(len(train))
print(len(test))
X_train, X_test = X[train], X[test] 
y_train, y_test = y[train], y[test]
print(len(X_train))
print(len(X_test))
print(len(y_train))
print(len(y_test))

print("__________")
print("hhoh",X_train.shape)
 """
 # create model
# 1D CNN neural network
model = Sequential()
model.add(Conv1D(filters=10, kernel_size=10, strides=1,activation='relu', input_shape=(4097,177)))
model.add(Conv1D(filters=10, kernel_size=10, strides=1))
model.add(MaxPooling1D(2))
model.add(Conv1D(30,10,activation='relu', strides=1))
model.add(Conv1D(30,10,activation='relu', strides=1))
model.add(MaxPooling1D(2))
model.add(Conv1D(60,10,activation='relu', strides=1))
model.add(Conv1D(60,10,activation='relu', strides=1))
model.add(MaxPooling1D(2))
model.add(Conv1D(90,10,activation='relu', strides=1))
model.add(Conv1D(90,10,activation='relu', strides=1))
model.add(MaxPooling1D(2))
model.add(Conv1D(120,10,activation='relu', strides=1))
model.add(Conv1D(120,10,activation='relu', strides=1))
model.add(MaxPooling1D(2))
#model.add(Flatten())
model.add(Dense(50))
model.add(Dense (20))
model.add(Dense (5,activation='softmax'))
print(model.summary())

# Compile model
model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])

#X_train = np.reshape(X_train,(X_train.shape[0], X_train.shape[1],1))
model.fit(X, y_train ,epochs=15, batch_size=3, verbose=0)
