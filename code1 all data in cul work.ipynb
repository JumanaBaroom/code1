{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('========\\n', array([ -24.,  -22.,  -17., ..., -155.,    6., -221.]))\n",
      "(';;;;;;;;;;;;;;;;;\\n', array([1., 1., 1., ..., 3., 3., 3.]))\n",
      "++++++++++++++++++++++++++++++++\n",
      "\n",
      "(1229100,)\n",
      "(1229100,)\n",
      "('New x_train shape: ', (327760, 1, 1), 'New y_train shape: ', (327760, 1, 1))\n",
      "('New x_train shape: ', (327760, 1, 1), 'New y_train shape: ', (327760, 1, 3))\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:87: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(4, 6, activation=\"relu\", data_format=\"channels_first\", input_shape=(1, 1), padding=\"same\", strides=1)`\n",
      "/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:88: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(4, 6, padding=\"same\", strides=1, activation=\"relu\")`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 4, 1)              28        \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 4, 4)              28        \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 1, 4)              0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 1, 4)              84        \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 1, 4)              84        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 1, 4)              0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 1, 4)              0         \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 1, 10)             170       \n",
      "_________________________________________________________________\n",
      "conv1d_6 (Conv1D)            (None, 1, 10)             410       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 1, 10)             0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 1, 10)             0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1, 10)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_7 (Conv1D)            (None, 1, 10)             410       \n",
      "_________________________________________________________________\n",
      "conv1d_8 (Conv1D)            (None, 1, 10)             410       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 1, 10)             0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1 (None, 1, 10)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_9 (Conv1D)            (None, 1, 15)             615       \n",
      "_________________________________________________________________\n",
      "conv1d_10 (Conv1D)           (None, 1, 15)             915       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 1, 15)             0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1 (None, 1, 15)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1, 50)             800       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1, 20)             1020      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1, 3)              63        \n",
      "=================================================================\n",
      "Total params: 5,037\n",
      "Trainable params: 5,037\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/20\n",
      "  1272/327760 [..............................] - ETA: 59:20 - loss: 0.8547 - acc: 1.0000"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Flatten, Reshape\n",
    "from keras.layers import Conv1D, MaxPooling1D,GlobalAveragePooling1D\n",
    "from keras.layers import Input, Flatten, Dense, Dropout,Concatenate\n",
    "#from keras.layers import LeakyReLU\n",
    "from keras.layers.advanced_activations import LeakyReLU, PReLU\n",
    "from keras.utils import np_utils\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from scipy import stats\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#dataset = pd.read_csv(\"sof.csv\")\n",
    "#x=dataset.iloc[0:409698,:].values\n",
    "#y=dataset.iloc[409700:,:].values\n",
    "\n",
    "#x = dataset[0:409699,:]\n",
    "#y = dataset[409700:,:]\n",
    "#y=dataset[0,1:3]\n",
    "#y = y.transpose()\n",
    "#x = x.transpose()\n",
    "\"\"\"\n",
    "dataset = np.loadtxt(\"sof.csv\",delimiter=\",\")\n",
    "x = dataset[0:409699,:]\n",
    "y = dataset[409700:,0:3]\n",
    "\"\"\"\n",
    "\n",
    "lables=[]\n",
    "\n",
    "dataset = np.loadtxt(\"sof copy.csv\",delimiter=\",\")\n",
    "x=dataset[0:409700,0]\n",
    "s=dataset[0:409700,2]\n",
    "o=dataset[0:409700,4]\n",
    "fet=np.concatenate((x, s,o), axis=None)\n",
    "\n",
    "y=dataset[0:409700,1]\n",
    "e=dataset[0:409700,3]\n",
    "u=dataset[0:409700,5]\n",
    "\n",
    "lables=np.concatenate((y, e,u), axis=None)\n",
    "\n",
    "print(\"========\\n\",fet)\n",
    "print(\";;;;;;;;;;;;;;;;;\\n\",lables)\n",
    "\n",
    "\n",
    "print(\"++++++++++++++++++++++++++++++++\\n\")\n",
    "print(lables.shape)\n",
    "\n",
    "\n",
    "print(fet.shape)\n",
    "\n",
    "\n",
    "#x = x.reshape(x.shape[0], x.shape[1],1)\n",
    "#y = y.reshape(y.shape[0],y.shape[1],1)\n",
    "#print('New x_train shape: ', x.shape , 'New y_train shape: ',y.shape )\n",
    "\n",
    "#y_hot = np_utils.to_categorical(y_train-1,3)\n",
    "#print('New x_train shape: ', x.shape , 'New y_train shape: ',y_hot.shape )\n",
    "\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=0)\n",
    "\n",
    "#print (y_train.shape)\n",
    "\n",
    "\n",
    "x_train = x_train.reshape(x_train.shape[0],1)\n",
    "x_train = x_train.reshape(x_train.shape[0],x_train.shape[1],1)\n",
    "\n",
    "\n",
    "y_train = y_train.reshape(y_train.shape[0],1)\n",
    "y_train = y_train.reshape(y_train.shape[0],x_train.shape[1],1)\n",
    "\n",
    "\n",
    "print('New x_train shape: ', x_train.shape , 'New y_train shape: ',y_train.shape )\n",
    "\n",
    "y_train_hot = np_utils.to_categorical(y_train-1,3)\n",
    "print('New x_train shape: ', x_train.shape , 'New y_train shape: ',y_train_hot.shape )\n",
    "\n",
    "\n",
    "print (x_train.ndim)\n",
    "\n",
    "model= Sequential()\n",
    "model.add(Conv1D(4, 6, strides=1,activation='relu',border_mode='same',input_shape=(1,1), data_format='channels_first'))\n",
    "model.add(Conv1D(4, 6, strides=1, activation='relu', border_mode='same'))\n",
    "model.add(MaxPooling1D(4, strides=2))\n",
    "#model.add(Dropout(0.15))\n",
    "model.add(Conv1D(4, 5, strides=1, activation='relu',padding='same',))\n",
    "model.add(Conv1D(4, 5, strides=1, activation='relu', padding='same'))\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(MaxPooling1D(4, strides=2, padding='same'))\n",
    "#model.add(Dropout(0.15))\n",
    "model.add(Conv1D(10, 4,strides=1 , activation='relu', padding='same'))\n",
    "model.add(Conv1D(10, 4,strides=1 , activation='relu', padding='same'))\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(MaxPooling1D(10, strides=2, padding='same'))\n",
    "model.add(Dropout(0.15))\n",
    "model.add(Conv1D(10, 4, strides=1 , activation='relu', padding='same'))\n",
    "model.add(Conv1D(10, 4, strides=1 , activation='relu', padding='same'))\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(MaxPooling1D(10, strides=2, padding='same'))\n",
    "#model.add(Dropout(0.15))\n",
    "model.add(Conv1D(15, 4, strides=1 , activation='relu', padding='same'))\n",
    "model.add(Conv1D(15, 4, strides=1 , padding='same'))\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(MaxPooling1D(15, strides=2 , padding='same'))\n",
    "#model.add(Dropout(0.15))\n",
    "\n",
    "#model.add(GlobalAveragePooling1D())\n",
    "#model.add(Dropout(0.15))\n",
    "model.add(Dense (50 , activation='relu'))\n",
    "#model.add(Dropout(0.15))\n",
    "model.add(Dense (20 , activation='relu'))\n",
    "#model.add(Dropout(0.15))\n",
    "model.add(Dense (3,activation='softmax'))\n",
    "print(model.summary())\n",
    "\"\"\"\n",
    "\n",
    "model= Sequential()\n",
    "model.add(Conv1D(4, 6, strides=1,input_shape=(1,3)))\n",
    "model.add(MaxPooling1D(4, strides=2))\n",
    "model.add(Conv1D(4, 5, strides=1, padding='same'))\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(MaxPooling1D(4, strides=2))\n",
    "model.add(Conv1D(10, 4,strides=1 , padding='same'))\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(MaxPooling1D(10, strides=2))\n",
    "\n",
    "model.add(Conv1D(10, 4, strides=1 , padding='same'))\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(MaxPooling1D(10, strides=2))\n",
    "model.add(Conv1D(15, 4, strides=1 , padding='same'))\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(MaxPooling1D(15, strides=2 , padding='same'))\n",
    "\n",
    "model.add(GlobalAveragePooling1D())\n",
    "model.add(Dropout(0.15))\n",
    "model.add(Dense (50))\n",
    "model.add(Dense (20))\n",
    "model.add(Dense (5,activation='softmax'))\n",
    "print(model.summary())\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# Compile model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Fit the model\n",
    "model.fit(x_train, y_train_hot, epochs=20, batch_size=3, verbose=1)\n",
    "\n",
    "# evaluate the model\n",
    "#scores = model.evaluate(x_test, y_test, verbose=0)\n",
    "\n",
    "\n",
    "#print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "#cvscores.append(scores[1] * 100)\n",
    "#print(\"%.2f%% (+/- %.2f%%)\" % (numpy.mean(cvscores), numpy.std(cvscores)))\n",
    "\n",
    "#print(\"\\n--- Fit the model ---\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
