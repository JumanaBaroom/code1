{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (<ipython-input-5-c71e5c7c09c2>, line 44)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-5-c71e5c7c09c2>\"\u001b[0;36m, line \u001b[0;32m44\u001b[0m\n\u001b[0;31m    model= Sequential()\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LeakyReLU\n",
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Flatten, Reshape, GlobalAveragePooling1D\n",
    "from keras.layers import Conv2D, MaxPooling2D, Conv1D, MaxPooling1D\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.layers import Input, Flatten, Dense, Dropout, Convolution2D, Conv2D, MaxPooling2D, Lambda, GlobalMaxPooling2D, GlobalAveragePooling2D, BatchNormalization, Activation, AveragePooling2D, Concatenate\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from keras.utils import np_utils\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.svm import SVR\n",
    "from scipy import stats\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "#dataset = np.loadtxt(\"seazure.csv\",delimiter=\",\")\n",
    "#x=dataset[2:4098,1:26]\n",
    "#y=dataset[1,]\n",
    "\n",
    "\n",
    "dataset = np.loadtxt(\"ofor10 comma.csv\",delimiter=\",\")\n",
    "print(dataset)\n",
    "\n",
    "x=dataset[1:40969,]\n",
    "y=dataset[1,]\n",
    "x = x.transpose()\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=0)\n",
    "\n",
    "print(x_train.shape)\n",
    "print (x_train.ndim)\n",
    "\"\"\"\"\n",
    "kfold = KFold(n_splits=10, random_state=None, shuffle=False)\n",
    "# enumerate splits\n",
    "for train, test in kfold.split(X):\n",
    "#print(\"train:\",train ,\"test:\",test)\n",
    "\"\"\"\"\n",
    "# 1D CNN neural network\n",
    "model= Sequential()\n",
    "model.add(Conv1D(4, 6, strides=1,input_shape=(4097,4)))\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(MaxPooling1D(4, strides=2))\n",
    "model.add(Conv1D(4, 5, strides=1))\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(MaxPooling1D(4, strides=2))\n",
    "model.add(Conv1D(10, 4,strides=1))\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(MaxPooling1D(10, strides=2))\n",
    "model.add(Conv1D(10, 4, strides=1))\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(MaxPooling1D(10, strides=2))\n",
    "model.add(Conv1D(15, 4, strides=1))\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(MaxPooling1D(15, strides=2))\n",
    "model.add(Dense (50))\n",
    "model.add(Dense (20))\n",
    "model.add(Dense (3,activation='softmax'))\n",
    "print(model.summary())\n",
    "\n",
    "# Compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# Fit the model\n",
    "model.fit(x_train, y_train, epochs=150, batch_size=3, verbose=0)\n",
    "\n",
    "#plt.plot(history.history['acc'], \"g--\", label=\"Accuracy of training data\")\n",
    "# evaluate the model\n",
    "#scores = model.evaluate(x_test, x_test, verbose=0)\n",
    "\n",
    "\n",
    "#print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "#cvscores.append(scores[1] * 100)\n",
    "#print(\"%.2f%% (+/- %.2f%%)\" % (numpy.mean(cvscores), numpy.std(cvscores)))\n",
    "\n",
    "#print(\"\\n--- Fit the model ---\\n\")\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Hyper-parameters\n",
    "BATCH_SIZE = 3\n",
    "EPOCHS = 150\n",
    "# Enable validation to use ModelCheckpoint and EarlyStopping callbacks.\n",
    "history = model_m.fit(X,\n",
    "                    Y,\n",
    "                    batch_size=BATCH_SIZE,\n",
    "                    epochs=EPOCHS,\n",
    "                    callbacks=callbacks_list,\n",
    "                    validation_split=0.2,\n",
    "                    verbose=1)\n",
    "                    def create_model(x_train, y_train, x_test, y_test):\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
